{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = t\n",
    "\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='/.data/', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter()\n",
    "\n",
    "network = Network()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "tb.close()\n",
    "\n",
    "# tensorboard - -logdir = ./runs/ ---> to run tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 47210 loss: 33439.98210132122\n",
      "epoch 1 total_correct: 51517 loss: 23193.794877827168\n",
      "epoch 2 total_correct: 52159 loss: 21075.26876181364\n",
      "epoch 3 total_correct: 52418 loss: 20527.27068811655\n",
      "epoch 4 total_correct: 52475 loss: 20289.772848784924\n",
      "epoch 5 total_correct: 52867 loss: 19194.725701212883\n",
      "epoch 6 total_correct: 52867 loss: 19271.2292984128\n",
      "epoch 7 total_correct: 52868 loss: 18900.85325539112\n",
      "epoch 8 total_correct: 52965 loss: 18633.73486995697\n",
      "epoch 9 total_correct: 53148 loss: 18337.95399814844\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "lr = 0.01\n",
    "\n",
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "comment = f'batch_size={batch_size}, lr={lr}'\n",
    "tb = SummaryWriter(comment=comment)\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader:  # Get Batch\n",
    "\n",
    "        images, labels = batch\n",
    "        preds = network(images)\n",
    "        # Calculate Loss\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "        # Calculate Gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    tb.add_scalar('Loss', total_loss, epoch)\n",
    "    tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "    # tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "    # tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "    # tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "\n",
    "    for name, weight in network.named_parameters():\n",
    "        tb.add_histogram(name,weight, epoch)\n",
    "        tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "\n",
    "tb.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorboard --logdir=/d:/jupyter/pytorch/runs to run tensorboard on a specified folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating run builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [1000,10000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(lr=0.01, batch_size=1000),\n",
       " Run(lr=0.01, batch_size=10000),\n",
       " Run(lr=0.001, batch_size=1000),\n",
       " Run(lr=0.001, batch_size=10000)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = RunBuilder.get_runs(params)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(lr=0.01, batch_size=1000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = runs[0]\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1000\n"
     ]
    }
   ],
   "source": [
    "print(run.lr, run.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(lr=0.01, batch_size=1000) 0.01 1000\n",
      "Run(lr=0.01, batch_size=10000) 0.01 10000\n",
      "Run(lr=0.001, batch_size=1000) 0.001 1000\n",
      "Run(lr=0.001, batch_size=10000) 0.001 10000\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(run, run.lr, run.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    lr=[.01, .001],\n",
    "    batch_size=[1000, 10000]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['lr', 'batch_size'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([[0.01, 0.001], [1000, 10000]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Run"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Run = namedtuple('Run', params.keys())\n",
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(lr=0.01, batch_size=1000),\n",
       " Run(lr=0.01, batch_size=10000),\n",
       " Run(lr=0.001, batch_size=1000),\n",
       " Run(lr=0.001, batch_size=10000)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "for v in product(*params.values()):\n",
    "    runs.append(Run(*v))\n",
    "\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fdfc438aa52f0892e0f1e32edadd5a705a5fdb677a332bfc527ba95bd30041a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
