{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layer = None\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = self.layer(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend to nn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.layer = None\n",
    "\n",
    "    def forward(self):\n",
    "        t = self.layer(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2 layers from dummy layer, linear layers and convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)              # conv net 1\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)           # conv net 2\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)                      #linear layer 1\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)                          #linear layer 2\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)                           #linear output layer\n",
    "\n",
    "\n",
    "    def forward(self, t):\n",
    "        # implement forward pass here\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = Network()\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=192, out_features=120, bias=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=120, out_features=60, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=60, out_features=10, bias=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.1038, -0.0727, -0.1155, -0.0929, -0.1945],\n",
       "          [ 0.0522, -0.1092, -0.1205, -0.0125, -0.1563],\n",
       "          [-0.1052, -0.0144, -0.0252,  0.1657, -0.1657],\n",
       "          [-0.1984, -0.1329,  0.1408,  0.0267,  0.1111],\n",
       "          [-0.0729, -0.0821, -0.1162, -0.0006, -0.0921]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0523, -0.1605,  0.0703, -0.1484,  0.1340],\n",
       "          [ 0.0248,  0.0812,  0.1748,  0.1621, -0.0417],\n",
       "          [-0.0118, -0.0671, -0.1705, -0.1249, -0.1941],\n",
       "          [-0.0179,  0.0705, -0.1512, -0.0130,  0.0139],\n",
       "          [-0.1221,  0.1498,  0.0909, -0.0394,  0.1494]]],\n",
       "\n",
       "\n",
       "        [[[-0.0143,  0.0318,  0.0423,  0.0129,  0.0916],\n",
       "          [-0.1154, -0.1110,  0.1530,  0.0865,  0.1727],\n",
       "          [-0.0985, -0.0947,  0.0461, -0.1436, -0.0497],\n",
       "          [ 0.0496, -0.0481, -0.1812, -0.1318, -0.1478],\n",
       "          [ 0.0878, -0.0331,  0.0258,  0.1279,  0.1126]]],\n",
       "\n",
       "\n",
       "        [[[-0.1387, -0.0979, -0.1810,  0.1080, -0.0987],\n",
       "          [-0.0927,  0.0927, -0.1627, -0.1854,  0.1715],\n",
       "          [-0.1778, -0.1700,  0.0979, -0.1830, -0.0474],\n",
       "          [-0.0524,  0.1958, -0.1473, -0.1961, -0.1305],\n",
       "          [-0.0037,  0.0352,  0.0813, -0.1461, -0.0103]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0845,  0.1502,  0.0919, -0.0759,  0.1091],\n",
       "          [-0.0600,  0.0368, -0.1976, -0.1809,  0.1833],\n",
       "          [ 0.1624,  0.0084,  0.0229,  0.1277,  0.1007],\n",
       "          [-0.1868, -0.0966,  0.0460,  0.1925,  0.1225],\n",
       "          [-0.1086,  0.1180,  0.1924, -0.0464,  0.1566]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0170,  0.1452,  0.0678,  0.0199, -0.1133],\n",
       "          [-0.0403, -0.1244, -0.1160, -0.0667,  0.0395],\n",
       "          [-0.0057, -0.1528, -0.0517, -0.1633,  0.0144],\n",
       "          [-0.1336, -0.0090, -0.0116, -0.0557,  0.1740],\n",
       "          [-0.0845, -0.1514, -0.1744,  0.0021,  0.1026]]]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 5, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 6, 5, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 192])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 120])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 60])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.out.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = torch.tensor([1,2,3,4], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = torch.tensor([\n",
    "    [1,2,3,4],\n",
    "    [2,3,4,5],\n",
    "    [3,4,5,6]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30., 40., 50.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix.matmul(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([12, 6, 5, 5])\n",
      "torch.Size([12])\n",
      "torch.Size([120, 192])\n",
      "torch.Size([120])\n",
      "torch.Size([60, 120])\n",
      "torch.Size([60])\n",
      "torch.Size([10, 60])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in network.parameters():\n",
    "    print(param.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "fc1.weight \t\t torch.Size([120, 192])\n",
      "fc1.bias \t\t torch.Size([120])\n",
      "fc2.weight \t\t torch.Size([60, 120])\n",
      "fc2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in network.named_parameters():\n",
    "    print(name, '\\t\\t', param.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5726f263798528542321b70a4a500cbf842fbef8cca9b039c5e3a78098777d3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('my_ml_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
